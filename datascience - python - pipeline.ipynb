{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/grsea.priv/util0745'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/tmdb-box-office-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv( '/home/grsea.priv/util0745/data/tmdb-box-office-prediction-train.csv' )\n",
    "\n",
    "df_test = pd.read_csv( '/home/grsea.priv/util0745/data/tmdb-box-office-prediction-test.csv' )\n",
    "\n",
    "df_y_test = pd.read_csv( '/home/grsea.priv/util0745/data/tmdb-box-office-prediction-sample-submission.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget</th>\n",
       "      <td>14000000</td>\n",
       "      <td>40000000</td>\n",
       "      <td>3300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homepage</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_id</th>\n",
       "      <td>tt2637294</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>tt2582802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_language</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_title</th>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Whiplash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overview</th>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>6.57539</td>\n",
       "      <td>8.24889</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poster_path</th>\n",
       "      <td>/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg</td>\n",
       "      <td>/w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg</td>\n",
       "      <td>/lIv1QinFqz4dlp5U4lQ6HaiskOZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_companies</th>\n",
       "      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n",
       "      <td>[{'name': 'Walt Disney Pictures', 'id': 2}]</td>\n",
       "      <td>[{'name': 'Bold Films', 'id': 2266}, {'name': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_countries</th>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>2/20/15</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>10/10/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>93</td>\n",
       "      <td>113</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoken_languages</th>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>Released</td>\n",
       "      <td>Released</td>\n",
       "      <td>Released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagline</th>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Whiplash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keywords</th>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cast</th>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crew</th>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>12314651</td>\n",
       "      <td>95149435</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0  \\\n",
       "id                                                                     1   \n",
       "belongs_to_collection  [{'id': 313576, 'name': 'Hot Tub Time Machine ...   \n",
       "budget                                                          14000000   \n",
       "genres                                    [{'id': 35, 'name': 'Comedy'}]   \n",
       "homepage                                                             NaN   \n",
       "imdb_id                                                        tt2637294   \n",
       "original_language                                                     en   \n",
       "original_title                                    Hot Tub Time Machine 2   \n",
       "overview               When Lou, who has become the \"father of the In...   \n",
       "popularity                                                       6.57539   \n",
       "poster_path                             /tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg   \n",
       "production_companies   [{'name': 'Paramount Pictures', 'id': 4}, {'na...   \n",
       "production_countries   [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "release_date                                                     2/20/15   \n",
       "runtime                                                               93   \n",
       "spoken_languages                [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "status                                                          Released   \n",
       "tagline                The Laws of Space and Time are About to be Vio...   \n",
       "title                                             Hot Tub Time Machine 2   \n",
       "Keywords               [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "cast                   [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "crew                   [{'credit_id': '59ac067c92514107af02c8c8', 'de...   \n",
       "revenue                                                         12314651   \n",
       "\n",
       "                                                                       1  \\\n",
       "id                                                                     2   \n",
       "belongs_to_collection  [{'id': 107674, 'name': 'The Princess Diaries ...   \n",
       "budget                                                          40000000   \n",
       "genres                 [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "homepage                                                             NaN   \n",
       "imdb_id                                                        tt0368933   \n",
       "original_language                                                     en   \n",
       "original_title                  The Princess Diaries 2: Royal Engagement   \n",
       "overview               Mia Thermopolis is now a college graduate and ...   \n",
       "popularity                                                       8.24889   \n",
       "poster_path                             /w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg   \n",
       "production_companies         [{'name': 'Walt Disney Pictures', 'id': 2}]   \n",
       "production_countries   [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "release_date                                                      8/6/04   \n",
       "runtime                                                              113   \n",
       "spoken_languages                [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "status                                                          Released   \n",
       "tagline                It can take a lifetime to find true love; she'...   \n",
       "title                           The Princess Diaries 2: Royal Engagement   \n",
       "Keywords               [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "cast                   [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "crew                   [{'credit_id': '52fe43fe9251416c7502563d', 'de...   \n",
       "revenue                                                         95149435   \n",
       "\n",
       "                                                                       2  \n",
       "id                                                                     3  \n",
       "belongs_to_collection                                                NaN  \n",
       "budget                                                           3300000  \n",
       "genres                                     [{'id': 18, 'name': 'Drama'}]  \n",
       "homepage                               http://sonyclassics.com/whiplash/  \n",
       "imdb_id                                                        tt2582802  \n",
       "original_language                                                     en  \n",
       "original_title                                                  Whiplash  \n",
       "overview               Under the direction of a ruthless instructor, ...  \n",
       "popularity                                                          64.3  \n",
       "poster_path                             /lIv1QinFqz4dlp5U4lQ6HaiskOZ.jpg  \n",
       "production_companies   [{'name': 'Bold Films', 'id': 2266}, {'name': ...  \n",
       "production_countries   [{'iso_3166_1': 'US', 'name': 'United States o...  \n",
       "release_date                                                    10/10/14  \n",
       "runtime                                                              105  \n",
       "spoken_languages                [{'iso_639_1': 'en', 'name': 'English'}]  \n",
       "status                                                          Released  \n",
       "tagline                  The road to greatness can take you to the edge.  \n",
       "title                                                           Whiplash  \n",
       "Keywords               [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...  \n",
       "cast                   [{'cast_id': 5, 'character': 'Andrew Neimann',...  \n",
       "crew                   [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  \n",
       "revenue                                                         13092000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head( 3 ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>3001</td>\n",
       "      <td>3002</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1        2\n",
       "id          3001     3002     3003\n",
       "revenue  1000000  1000000  1000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test.head( 3 ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train comporte la colonne à prédire revenue\n",
    "# df_test n'a pas cette colonne. Elle est dans df_y_test.\n",
    "\n",
    "\n",
    "lst_col_keep = [ 'budget' , 'popularity' , 'runtime' , 'original_language' , 'status' , 'revenue' ]\n",
    "\n",
    "lst_X_col = [ 'budget' , 'popularity' , 'runtime' , 'original_language' , 'status' ]\n",
    "\n",
    "lst_y_col = [ 'revenue' ]\n",
    "\n",
    "\n",
    "X_train = df_train[ lst_X_col ]\n",
    "\n",
    "X_test = df_test[ lst_X_col ]\n",
    "\n",
    "\n",
    "y_train = df_train[ lst_y_col ]\n",
    "\n",
    "y_test = df_y_test[ lst_y_col ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pour variables continues\n",
    "\n",
    "lst_col_cont = [ 'budget' , 'popularity' , 'runtime' ]\n",
    "\n",
    "cont_pipeline = make_pipeline( SimpleImputer(strategy = 'median' ) ,\n",
    "                               PowerTransformer( method = 'yeo-johnson' , standardize = False ) ,\n",
    "                               StandardScaler( ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pour variables catégorielles\n",
    "\n",
    "lst_col_cat = [ 'original_language' , 'status' ]\n",
    "\n",
    "cat_pipeline = make_pipeline( SimpleImputer( strategy = 'constant' , fill_value = 'unknown' ) ,\n",
    "                              OneHotEncoder( handle_unknown = 'ignore' ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor\n",
    "\n",
    "preprocessor = ColumnTransformer( transformers = [ ( 'continuous' , cont_pipeline , lst_col_cont ) ,\n",
    "                                                   ( 'categorical' , cat_pipeline , lst_col_cat ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.linear_model import LassoLars\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "\n",
    "# \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation de différents modèles :\n",
    "\n",
    "def mdl_eval ( pipeline , X_train , y_train , X_test , y_test ):\n",
    "    \n",
    "    # Entrainement sur X_train , y_train :\n",
    "    pipeline.fit( X_train , y_train )\n",
    "    \n",
    "    # Prédiction sur X_train :\n",
    "    y_train_pred = pipeline.predict( X_train ) \n",
    "    \n",
    "    # Prédiction sur X_test :\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Performance y_train vs. y_train_pred :\n",
    "    train_score = np.sqrt(mean_squared_error(y_train, y_train_pred ) )\n",
    "    \n",
    "    # Performance y_test vs. y_test_pred :\n",
    "    test_score = np.sqrt(mean_squared_error(y_test, y_test_pred ) ) \n",
    "    \n",
    "    return pipeline.named_steps[ 'regressor' ] , train_score , test_score\n",
    "    # step regressor dans pipeline obligatoire ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-3557e6ddac79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                ( 'regressor', r ) ] )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmdl_eval\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-80-3984af67e6dd>\u001b[0m in \u001b[0;36mmdl_eval\u001b[1;34m(pipeline, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Entrainement sur X_train , y_train :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Prédiction sur X_train :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, Xy)\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \"\"\"\n\u001b[1;32m--> 698\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpha'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    515\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    319\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "# TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\n",
    "# voir : https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "\n",
    "regressors = [ LinearRegression(),\n",
    "               Lasso(alpha=.5),\n",
    "               Ridge(alpha=.1),\n",
    "               LassoLars(alpha=.1),\n",
    "               DecisionTreeRegressor(),\n",
    "               RandomForestRegressor(),\n",
    "               AdaBoostRegressor(),\n",
    "               GradientBoostingRegressor() ]\n",
    "\n",
    "\n",
    "for r in regressors :\n",
    "    pipe = Pipeline( steps = [ ('preprocessor', preprocessor ) ,\n",
    "                               ( 'regressor', r ) ] )\n",
    "    \n",
    "    mdl_eval( pipe , X_train , y_train , X_test , y_test )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "metier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
