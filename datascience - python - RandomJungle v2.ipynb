{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn as skl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeux de données artificiel\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 60000 , \n",
    "                           n_features = 25 , \n",
    "                           n_informative = 15 ,\n",
    "                           n_redundant = 0 , \n",
    "                           n_repeated = 0 , \n",
    "                           n_classes = 2 ,\n",
    "                           n_clusters_per_class = 1 ,\n",
    "                           weights =[ 0.99 , 0.01 ] ,\n",
    "                           class_sep = 1.0 , \n",
    "                           random_state = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations en dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables explicatives :\n",
    "\n",
    "X_var = [ 'x_' + str( k ) for k in range( 0 , X.shape[1] ) ]\n",
    "\n",
    "# Variable à expliquer :\n",
    "\n",
    "y_var = [ 'y' ]\n",
    "\n",
    "# Dataframes : \n",
    "\n",
    "df_X = pd.DataFrame( X , columns = X_var )\n",
    "\n",
    "df_y = pd.DataFrame( y , columns = y_var )\n",
    "\n",
    "# Empilement de df_X et df_y :\n",
    "\n",
    "df = pd.concat( [ df_X , df_y ] , axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_all : (54000, 26)\n",
      "df_train_0 : (53197, 26)\n",
      "df_train_1 : (803, 26)\n",
      "df_test : (6000, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAB\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_train_all , df_test = train_test_split( df , train_size = 0.9 )\n",
    "\n",
    "df_train_0 = df_train_all[ df_train_all[ 'y' ] == 0 ]\n",
    "df_train_1 = df_train_all[ df_train_all[ 'y' ] == 1 ]\n",
    "\n",
    "print( 'df_train_all : {0}'.format( df_train_all.shape ) )\n",
    "print( 'df_train_0 : {0}'.format( df_train_0.shape ) )\n",
    "print( 'df_train_1 : {0}'.format( df_train_1.shape ) )\n",
    "\n",
    "print( 'df_test : {0}'.format( df_test.shape ) )\n",
    "\n",
    "# train dataset :\n",
    "\n",
    "df_X_train_all = df_train_all[ X_var ]\n",
    "df_y_train_all = df_train_all[ y_var ]\n",
    "\n",
    "X_train_all = df_X_train_all.values\n",
    "y_train_all = np.ravel( df_y_train_all.values )\n",
    "\n",
    "# test dataset :\n",
    "\n",
    "df_X_test = df_test[ X_var ]\n",
    "df_y_test = df_test[ y_var ]\n",
    "\n",
    "X_test = df_X_test.values\n",
    "y_test = np.ravel( df_y_test.values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies pour modélisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Baseline :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline | auc (test dataset) : \n",
      " 0.60\n",
      "baseline | confusion matrix (test dataset) : \n",
      " [[5904    1]\n",
      " [  76   19]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle de référence ( RandomForest ) pour comparaison avec modèle cible ( RandomJungle )\n",
    "\n",
    "clf = RandomForestClassifier( n_estimators = 10 )\n",
    "\n",
    "clf.fit( X_train_all , y_train_all )\n",
    "\n",
    "# Sauvegarde du modèle sur disque\n",
    "filename = './mdl/_mdl' + '.sav'\n",
    "pickle.dump( clf , open( filename , 'wb' ) )\n",
    "    \n",
    "    \n",
    "# Prédictions sur test dataset\n",
    "y_test_pred = clf.predict( X_test )\n",
    "    \n",
    "# Matrice de confusion sur test dataset\n",
    "cfu_mtx = confusion_matrix( y_test , y_test_pred )\n",
    "    \n",
    "# AUC sur test dataset\n",
    "auc = roc_auc_score( y_test , y_test_pred )\n",
    "    \n",
    "#print( 'confusion matrix (test dataset):\\n {0}'.format( cfu_mtx ) )\n",
    "print( 'baseline | auc (test dataset) : \\n {0:.2f}'.format( auc ) )\n",
    "print( 'baseline | confusion matrix (test dataset) : \\n {0}'.format( cfu_mtx ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font : color = 'orange'> Modèle RandomJungle = K RandomForest </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomJungle( N , K ) :\n",
    "    \n",
    "    \"\"\"\n",
    "     BaseLine vs RandomForest : \n",
    "      * N : nombre d'expériences \n",
    "      * K : nombre d'échantillons de cas négatifs mis en face des cas positifs\n",
    "      \n",
    "      Expérience : K tirages dans les cas négatifs mis en face des cas positifs\n",
    "    \"\"\"\n",
    "    \n",
    "    lst_bsl_auc = []\n",
    "    lst_randjgl_auc = []\n",
    "    \n",
    "    for i in range( N ) :\n",
    "        \n",
    "        # [ 0 ] Train / test split :\n",
    "        df_train_all , df_test = train_test_split( df , train_size = 0.9 , test_size = 0.1 )\n",
    "\n",
    "        df_train_0 = df_train_all[ df_train_all[ 'y' ] == 0 ]\n",
    "        df_train_1 = df_train_all[ df_train_all[ 'y' ] == 1 ]\n",
    "        \n",
    "        # [ 0.1 ] train dataset :\n",
    "\n",
    "        df_X_train_all = df_train_all[ X_var ]\n",
    "        df_y_train_all = df_train_all[ y_var ]\n",
    "\n",
    "        X_train_all = df_X_train_all.values\n",
    "        y_train_all = np.ravel( df_y_train_all.values )\n",
    "\n",
    "        # [ 0.2 ] test dataset :\n",
    "\n",
    "        df_X_test = df_test[ X_var ]\n",
    "        df_y_test = df_test[ y_var ]\n",
    "\n",
    "        X_test = df_X_test.values\n",
    "        y_test = np.ravel( df_y_test.values )\n",
    "        \n",
    "        # [ 1 ] Baseline :\n",
    "        \n",
    "        clf = RandomForestClassifier( n_estimators = 100 )\n",
    "        #clf = svm.LinearSVC()\n",
    "        #clf = LogisticRegression( random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "        #clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2) ) \n",
    "        #clf =  AdaBoostClassifier()\n",
    "        #clf = QuadraticDiscriminantAnalysis()\n",
    "        #clf = GaussianNB()\n",
    "        \n",
    "        clf.fit( X_train_all , y_train_all )\n",
    "        y_test_pred = clf.predict( X_test )\n",
    "        auc = roc_auc_score( y_test , y_test_pred )\n",
    "        lst_bsl_auc.append( auc )\n",
    "        print( '[ i : {0} | baseline | auc ( test dataset ) : {1:.4f} ]'.format( i , auc ) )\n",
    "        \n",
    "        \n",
    "        # [ 2 ] RandomJungle :\n",
    "        \n",
    "        # Dictionnaire pour stockage des K prédictions\n",
    "        #pred_train = {}\n",
    "        \n",
    "        lst_auc = []\n",
    "        # RandomJungle - Taille des échantillons à mettre en face des fraudes :\n",
    "        spl_siz = len( df_train_1.index )\n",
    "        \n",
    "        # RandomJungle - K RandomForest()\n",
    "        for j in range( 0 , K ) :\n",
    "            # RandomJungle - train dataset - échantillon de sinistres non fraude (autant que de sinistres fraude dans le train dataset)\n",
    "            df_train_0_spl = df_train_0.sample( n =  spl_siz ) \n",
    "            # RandomJungle - train dataset - concaténation des sinistres fraude et de l'échantillon de sinistres non fraude\n",
    "            df_tmp = pd.concat( [ df_train_1 , df_train_0_spl ] , axis = 0 )\n",
    "    \n",
    "            df_X_train = df_tmp[ X_var ]\n",
    "            df_y_train = df_tmp[ y_var ]\n",
    "    \n",
    "            X_train = df_X_train.values\n",
    "            y_train = np.ravel( df_y_train.values )\n",
    "    \n",
    "            clf = RandomForestClassifier( n_estimators = 100 )\n",
    "            #clf = svm.LinearSVC()\n",
    "            #clf = LogisticRegression( solver='lbfgs', multi_class='ovr' )\n",
    "            #clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2) ) \n",
    "            #clf =  AdaBoostClassifier()\n",
    "            #clf = QuadraticDiscriminantAnalysis()\n",
    "            #clf = GaussianNB()\n",
    "            \n",
    "            clf.fit( X_train , y_train )\n",
    "     \n",
    "            # RandomJungle - Sauvegarde des modèles sur disque\n",
    "            filename = './mdl/_mdl_' + str( i ) + '_' + str( j ) + '.sav'\n",
    "            pickle.dump( clf , open( filename , 'wb' ) )\n",
    "    \n",
    "            # RandomJungle - Prédictions sur test dataset\n",
    "            y_test_pred = clf.predict( X_test )\n",
    "    \n",
    "            # RandomJungle - AUC sur test dataset\n",
    "            auc = roc_auc_score( y_test , y_test_pred )\n",
    "            lst_auc.append( auc )\n",
    "            #print( 'i : {0} | j : {1} | RandomForest | auc (test dataset) : \\n {2}'.format( i , j , auc ) )\n",
    "    \n",
    "        \n",
    "        pred = {}\n",
    "\n",
    "        for j in range( K ) :\n",
    "            filename = './mdl/_mdl_' + str( i ) + '_' + str( j ) + '.sav'\n",
    "            clf = pickle.load( open( filename , 'rb' ) )\n",
    "            y_test_pred = clf.predict( X_test )\n",
    "            col = 'y_pred_' + str( j )\n",
    "            pred[ col ] = y_test_pred\n",
    "    \n",
    "        df_X_test_pred = pd.DataFrame( pred )\n",
    "        df_X_test_pred = df_X_test_pred[ sorted( df_X_test_pred.columns ) ]\n",
    "        \n",
    "        df_X_test_pred[ 'cons' ] = df_X_test_pred.sum( axis = 1 ).apply( lambda x : ( K - x ) / K )\n",
    "        df_X_test_pred[ 'y_pred' ] = np.where( df_X_test_pred[ 'cons' ] < 0.50 , 1 , 0 )\n",
    "        df_X_test_pred[ 'y_real' ] = y_test\n",
    "        \n",
    "        auc = roc_auc_score( y_test , df_X_test_pred[ 'y_pred' ] )\n",
    "        print( '[ i : {0} | RandomJungle | auc ( test dataset ) : {1:.4f} ]'.format( i , auc ) )\n",
    "        lst_randjgl_auc.append( auc )\n",
    " \n",
    "    return lst_bsl_auc , lst_randjgl_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ i : 0 | baseline | auc ( test dataset ) : 0.5746 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9b041bf5b4e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbsl_vs_randjgl_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomJungle\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-5012600e0ed8>\u001b[0m in \u001b[0;36mRandomJungle\u001b[1;34m(N, K)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;31m# RandomJungle - Prédictions sur test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;31m# RandomJungle - AUC sur test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \"\"\"\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    594\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[0;32m    595\u001b[0m                                             lock)\n\u001b[1;32m--> 596\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \"\"\"\n\u001b[1;32m--> 389\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bsl_vs_randjgl_auc = RandomJungle( N = 10 , K = 500 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Baseline vs RandomJungle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-24.84841468338586, pvalue=2.2061887261919884e-15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "np.mean( bsl_vs_randjgl_auc[1] )\n",
    "\n",
    "np.std( bsl_vs_randjgl_auc[1] )\n",
    "\n",
    "\n",
    "# Différence significative entre AUC modèle Baseline vs RandomJungle :\n",
    "\n",
    "ttest_ind( bsl_vs_randjgl_auc[0] , bsl_vs_randjgl_auc[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphe : AUC modèle Baseline vs RandomJungle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = [ np.mean( bsl_vs_randjgl_auc[0] ) , np.mean( bsl_vs_randjgl_auc[1] ) ]\n",
    "bar_lbl = [ 'AUC(Baseline)' , 'AUC (RandomJungle)' ]\n",
    "y_pos = np.arange( len( bar_lbl ) )\n",
    "\n",
    "plt.barh( y_pos , h )\n",
    "\n",
    "plt.yticks( y_pos , bar_lbl )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910356704740045"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "pca = PCA( n_components = 15 )\n",
    "\n",
    "\n",
    "# Non fraudes :\n",
    "\n",
    "df_X_train_1 = df_train_1[ X_var ]\n",
    "\n",
    "df_X_train_1_scl = scale( df_X_train_1 )\n",
    "\n",
    "pca.fit_transform( df_X_train_1_scl )\n",
    "\n",
    "sum( pca.explained_variance_ratio_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=1, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = 10\n",
    "\n",
    "clus = KMeans( n_clusters = K , n_init = 10 , random_state = 1 )\n",
    "\n",
    "clus.fit( df_X_train_1_scl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_1_scl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 6, 6, 0, 3, 1, 5, 8, 9, 6, 9, 5, 0, 4, 8, 0, 3, 1, 7, 5, 0,\n",
       "       6, 0, 3, 7, 8, 3, 2, 1, 8, 9, 8, 0, 4, 0, 3, 2, 4, 1, 1, 4, 4, 7,\n",
       "       8, 0, 3, 8, 2, 4, 1, 1, 8, 6, 5, 7, 6, 2, 6, 3, 9, 5, 8, 5, 6, 6,\n",
       "       0, 6, 2, 9, 6, 0, 6, 7, 2, 5, 6, 2, 4, 2, 7, 0, 3, 1, 4, 7, 3, 9,\n",
       "       8, 2, 1, 7, 7, 8, 3, 8, 7, 2, 9, 4, 9, 7, 9, 7, 8, 3, 1, 9, 1, 7,\n",
       "       7, 3, 1, 9, 3, 5, 2, 0, 9, 6, 8, 0, 3, 9, 2, 2, 3, 6, 0, 8, 4, 9,\n",
       "       7, 9, 2, 8, 9, 4, 5, 9, 9, 5, 2, 7, 7, 9, 5, 1, 0, 0, 1, 4, 5, 8,\n",
       "       5, 2, 9, 4, 0, 5, 9, 2, 0, 4, 5, 0, 5, 6, 9, 3, 7, 5, 1, 9, 3, 1,\n",
       "       5, 9, 2, 3, 5, 5, 0, 1, 5, 0, 6, 0, 6, 6, 8, 0, 3, 5, 5, 1, 9, 8,\n",
       "       5, 0, 4, 1, 5, 3, 7, 9, 0, 9, 4, 2, 0, 8, 2, 7, 5, 2, 8, 5, 2, 5,\n",
       "       9, 7, 4, 9, 4, 1, 3, 3, 7, 4, 0, 2, 4, 2, 9, 1, 4, 3, 8, 5, 1, 5,\n",
       "       4, 4, 4, 1, 5, 6, 2, 5, 5, 1, 9, 5, 4, 4, 1, 1, 8, 6, 6, 2, 7, 8,\n",
       "       7, 4, 1, 5, 4, 3, 4, 8, 8, 3, 2, 6, 8, 4, 7, 5, 5, 2, 9, 2, 7, 1,\n",
       "       7, 6, 3, 9, 2, 6, 3, 4, 7, 2, 6, 3, 9, 7, 7, 1, 5, 7, 9, 4, 0, 0,\n",
       "       4, 2, 6, 1, 7, 5, 8, 6, 5, 3, 0, 6, 4, 3, 5, 4, 7, 0, 1, 7, 5, 0,\n",
       "       1, 3, 8, 1, 6, 5, 1, 5, 6, 3, 4, 7, 9, 0, 3, 4, 2, 0, 5, 2, 5, 3,\n",
       "       9, 8, 3, 2, 1, 7, 0, 8, 7, 6, 7, 8, 6, 3, 2, 0, 3, 3, 8, 9, 3, 3,\n",
       "       6, 1, 0, 3, 5, 0, 3, 3, 5, 7, 4, 4, 8, 5, 6, 8, 2, 4, 4, 8, 4, 8,\n",
       "       5, 6, 4, 9, 9, 2, 1, 2, 8, 0, 3, 3, 2, 5, 5, 0, 4, 5, 8, 5, 6, 8,\n",
       "       9, 0, 9, 9, 8, 1, 1, 6, 6, 1, 6, 1, 8, 8, 5, 5, 4, 7, 0, 9, 7, 2,\n",
       "       2, 8, 1, 8, 5, 0, 8, 4, 9, 4, 3, 9, 7, 0, 9, 1, 3, 1, 5, 7, 3, 5,\n",
       "       9, 4, 8, 9, 0, 4, 3, 1, 2, 0, 5, 6, 7, 3, 1, 7, 5, 7, 3, 9, 5, 7,\n",
       "       1, 0, 8, 6, 4, 5, 9, 4, 0, 7, 4, 9, 4, 8, 1, 8, 4, 3, 2, 6, 0, 9,\n",
       "       0, 3, 5, 5, 8, 6, 1, 6, 0, 6, 7, 9, 8, 8, 6, 8, 3, 5, 8, 9, 2, 0,\n",
       "       7, 8, 9, 2, 0, 9, 9, 9, 4, 3, 7, 5, 9, 9, 4, 6, 3, 4, 7, 0, 9, 6,\n",
       "       1, 2, 6, 3, 4, 2, 1, 8, 9, 3, 9, 3, 5, 5, 9, 7, 6, 5, 7, 7, 2, 6,\n",
       "       5, 5, 0, 5, 6, 0, 6, 9, 5, 1, 0, 1, 8, 2, 4, 5, 5, 8, 1, 2, 8, 5,\n",
       "       4, 6, 7, 9, 9, 9, 3, 6, 8, 4, 4, 7, 1, 2, 4, 0, 2, 4, 5, 2, 0, 9,\n",
       "       2, 0, 3, 1, 9, 9, 9, 0, 2, 4, 4, 9, 8, 3, 2, 3, 5, 3, 1, 5, 4, 5,\n",
       "       0, 5, 7, 4, 8, 6, 2, 4, 2, 4, 6, 2, 3, 4, 9, 1, 3, 5, 4, 1, 6, 5,\n",
       "       5, 5, 2, 9, 3, 1, 5, 6, 9, 4, 5, 3, 9, 4, 8, 1, 3, 3, 9, 6, 2, 7,\n",
       "       3, 9, 8, 5, 7, 0, 4, 6, 8, 3, 3, 9, 3, 8, 1, 8, 7, 2, 4, 3, 4, 6,\n",
       "       3, 7, 9, 9, 0, 7, 1, 7, 6, 6, 0, 9, 8, 5, 9, 1, 4, 4, 3, 9, 9, 9,\n",
       "       0, 4, 3, 1, 3, 0, 1, 8, 9, 0, 0, 4, 3, 9, 6, 3, 4, 7, 9, 8, 5, 8,\n",
       "       8, 0, 5, 0, 2, 5, 7, 8, 2, 5, 6, 9, 8, 0, 3, 0, 3, 9, 4, 4, 1, 9,\n",
       "       5, 7, 3, 5, 0, 5, 5, 4, 3, 3, 4, 7, 0, 6, 1, 2, 3, 6, 4, 8, 8, 3,\n",
       "       5, 0, 5, 8, 8, 3, 9, 9, 2, 7, 0, 8, 9, 9, 9, 3, 8, 4, 4, 2, 3, 0,\n",
       "       4, 8, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 15 features, expected 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-627e71515da4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf_train_0\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mX_var\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    937\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[0;32m    938\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[1;32m--> 939\u001b[1;33m                                  n_features, expected_n_features))\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incorrect number of features. Got 15 features, expected 25"
     ]
    }
   ],
   "source": [
    "clus.transform( pca.fit_transform( scale( df_train_0[ X_var ] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
